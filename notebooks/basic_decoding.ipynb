{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Decoding with ANOVA + SVM: face vs house in the Haxby dataset\n",
    "\n",
    "This example does a simple but efficient decoding on the Haxby dataset:\n",
    "using a feature selection, followed by an SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is decoding ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='../images/decoding_pipeline_example.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A schematic representation of standard decoding workflow/pipeline. The input (data) is prepared and potentially preprocessed before being submitted to a model that then utilizes a certain metric to provide a certain output.Image taken from https://main-educational.github.io/brain_encoding_decoding/haxby_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Haxby Dataset\n",
    "\n",
    "The dataset comes from one of the first studies which have demonstrated the feasibility of brain decoding was the study by Haxby and colleagues (2001).\n",
    "Subjects were presented with various images drawn from different categories (face, houses, cats, bottle, scrambled, scissors, shoe, chair) interleaved with resting periods. \n",
    "Subsequently a decoding model used to predict the presented categories based on the brain activity/responses. In the respective parts of this session, we will try to do the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the files of the Haxby dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nilearn to fetch the data\n",
    "from nilearn import datasets\n",
    "\n",
    "# By default 2nd subject will be fetched\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "func_img = haxby_dataset.func[0]\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('Mask nifti image (3D) is located at: %s' % haxby_dataset.mask)\n",
    "print('Functional nifti image (4D) is located at: %s' %\n",
    "      func_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the fmri data we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the mean image of the series, because it's hard to plot a 4D image\n",
    "from nilearn.image import mean_img\n",
    "func_image_mean = mean_img(func_img)\n",
    "\n",
    "from nilearn.plotting import view_img\n",
    "view_img(func_image_mean, cmap='magma', symmetric_cmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the image is not exactly in MNI space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the brain mask we got\n",
    "\n",
    "For this, we overlay it on the anatomical image. Note that the correspondence is poor, but making will most likely remove ou-of-brain regions, which is a good thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_roi\n",
    "plot_roi( haxby_dataset.mask, bg_img=haxby_dataset.anat[0],\n",
    "                  cmap='Paired', dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the stimuli used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For that, you need to get the stimulus information\n",
    "import matplotlib.pyplot as plt\n",
    "haxby_dataset_ = datasets.fetch_haxby(subjects=[], fetch_stimuli=True)\n",
    "stimulus_information = haxby_dataset_.stimuli\n",
    "\n",
    "# Read the stimulus images and plot them\n",
    "for stim_type in stimulus_information:\n",
    "  # skip control images, there are too many\n",
    "  if stim_type != 'controls':\n",
    "\n",
    "     file_names = stimulus_information[stim_type]\n",
    "     file_names = file_names[0:16]\n",
    "     fig, axes = plt.subplots(4, 4)\n",
    "     fig.suptitle(stim_type)\n",
    "\n",
    "     for img_path, ax in zip(file_names, axes.ravel()):\n",
    "         ax.imshow(plt.imread(img_path), cmap=plt.cm.gray)\n",
    "\n",
    "     for ax in axes.ravel():\n",
    "         ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target information as string and give a numerical identifier to each\n",
    "import pandas as pd\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "conditions = behavioral['labels']\n",
    "print(conditions.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a BIDS-compatible events file for plotting\n",
    "# we have no information of event duration, so we assume that it is 1 (in TR units)\n",
    "event_dictionary = {'onset': conditions.index,\n",
    "                    'trial_type':conditions.values,\n",
    "                    'duration': [1]* len(conditions)}\n",
    "events = pd.DataFrame(event_dictionary )\n",
    "\n",
    "# plot the event structure\n",
    "from nilearn.plotting import plot_event, show\n",
    "plot_event(events, figsize=(15, 4))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the analysis to faces and places\n",
    "from nilearn.image import index_img\n",
    "condition_mask = behavioral['labels'].isin(['face', 'house'])\n",
    "conditions = conditions[condition_mask]\n",
    "func_img = index_img(func_img, condition_mask)\n",
    "\n",
    "# Confirm that we now have 2 conditions\n",
    "print(conditions.unique())\n",
    "\n",
    "# The number of the session is stored in the CSV file giving the behavioral\n",
    "# data. We have to apply our session mask, to select only faces and houses.\n",
    "session_label = behavioral['chunks'][condition_mask]\n",
    "\n",
    "# plot that stuff\n",
    "event_dictionary = {'onset': conditions.index,\n",
    "                    'trial_type':conditions.values,\n",
    "                    'duration': [1]* len(conditions)}\n",
    "events = pd.DataFrame(event_dictionary)\n",
    "plot_event(events, figsize=(15, 4))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We directly associate labels with images, forgetting about hemodynamic delay (!) Well, this is what Haxby did. It is not fully unreasonable, given of the block structure of the design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA pipeline with :class:`nilearn.decoding.Decoder` object\n",
    "\n",
    "Nilearn Decoder object aims to provide smooth user experience by acting as a\n",
    "pipeline of several tasks: preprocessing with NiftiMasker, reducing dimension\n",
    "by selecting only relevant features with ANOVA -- a classical univariate\n",
    "feature selection based on F-test, and then decoding with different types of\n",
    "estimators (in this example is Support Vector Machine with a linear kernel)\n",
    "on nested cross-validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a SVC ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../images/optimal-hyperplane.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Support Vector Classifier aims at finding an optimal hyperplane to separate two classes in high-dimensional space, while maximizing the margin. Image from the scikit-learn SVM documentation under BSD 3-Clause license. Note that the above image is misleading because in reality, images live in a very high-dimensional space (= the number of voxels), which is barely populated with the few samples we provided. Yet the intuition of an \"optimal hyperplane\" remains valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an ANOVA ?\n",
    "\n",
    "It is a statistic that measures how strongly the signal in the voxel is explained by associated stimulus. Tehcnically, the statistic is analogous to the F statistic used in parametric mapping: the voxels with high F value are those you should retain to inform the classifier !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do an ANOVA-based voxel selection followed by an SVC ?\n",
    "\n",
    "There are 2 main reasons to do it:\n",
    "* Fitting an SVC is costly, hence fitting it on reduced data will save computation time\n",
    "* It can also benefit accuracy, because it amounts to removing noisy voxels that may degrade (a bit) classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import Decoder\n",
    "# Here screening_percentile is set to 5 percent\n",
    "screening_percentile = 5\n",
    "# since we work on minimally preprocessed data, smoothing should be beneficial\n",
    "smoothing_fwhm = 4\n",
    "# For decoding, standardizing is often very important. Hence, standardize=True\n",
    "\n",
    "decoder = Decoder(estimator='svc', \n",
    "                  mask=haxby_dataset.mask, \n",
    "                  smoothing_fwhm=smoothing_fwhm,\n",
    "                  standardize=True, \n",
    "                  screening_percentile=screening_percentile,\n",
    "                  scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the decoder and predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.fit(func_img, conditions)\n",
    "y_pred = decoder.predict(func_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for this classification task both classes contain the same number of samples (the problem is balanced). Then, we can use accuracy to measure the performance of the decoder. This is done by defining accuracy as the scoring. Let’s measure the prediction accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_pred == conditions).sum() / float(len(conditions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction accuracy score is meaningless. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain prediction scores via cross validation\n",
    "Define the cross-validation scheme used for validation. Here we use a\n",
    "LeaveOneGroupOut cross-validation on the session group which corresponds to a\n",
    "leave a session out scheme, then pass the cross-validator object to the cv\n",
    "parameter of decoder.leave-one-session-out For more details please take a\n",
    "look at:https://nilearn.github.io/dev/auto_examples/00_tutorials/plot_decoding_tutorial.html#sphx-glr-auto-examples-00-tutorials-plot-decoding-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "cv = LeaveOneGroupOut()\n",
    "\n",
    "decoder = Decoder(estimator='svc',\n",
    "                  mask=haxby_dataset.mask,\n",
    "                  standardize=True,\n",
    "                  screening_percentile=5,\n",
    "                  scoring='accuracy',\n",
    "                  cv=cv)\n",
    "\n",
    "# Compute the prediction accuracy for the different folds (i.e. session)\n",
    "# now we need to provide the groups information ta fitting time\n",
    "decoder.fit(func_img, conditions, groups=session_label)\n",
    "\n",
    "# Print the CV scores\n",
    "print(decoder.cv_scores_['face'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist other cross validation schemes: 5-fold, Shiffle Split etc. Note that it is advisable that the cross-validation structure be consistent with data organization: e.g. LeaveOneGroupout, or LeavePGroupOut, where groups can correspond to runs, sessions or individuals. The zoology of cross-validation models  can be found in https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on hyperparameters\n",
    "\n",
    "Note that when no hyperparameters are specified, the classifier will used default ones, e.g. C=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoder.cv_params_['face'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may instead provide a grid of parameters, among which the classifier will pick the best ones with nested cross-validation. This will impact accruacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 10., 100., 1000., 10000.]}\n",
    "decoder = Decoder(estimator='svc', \n",
    "                  mask=haxby_dataset.mask,\n",
    "                  standardize=True,\n",
    "                  screening_percentile=5,\n",
    "                  scoring='accuracy',\n",
    "                  cv=cv,\n",
    "                  param_grid=param_grid)\n",
    "decoder.fit(func_img, conditions, groups=session_label)\n",
    "print(decoder.cv_scores_['face'])\n",
    "print(decoder.cv_params_['face'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results\n",
    "Look at the SVC's discriminating weights using\n",
    ":class:`nilearn.plotting.plot_stat_map`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_img = decoder.coef_img_['face']\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "plot_stat_map(weight_img,\n",
    "              bg_img=haxby_dataset.anat[0],\n",
    "              title='SVM weights',\n",
    "              dim=-1)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can plot the weights using :class:`nilearn.plotting.view_img` as a\n",
    "dynamic html viewer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import view_img\n",
    "view_img(weight_img,\n",
    "         bg_img=haxby_dataset.anat[0],\n",
    "         title=\"SVM weights\",\n",
    "         dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the results as a Nifti file may also be important\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_img.to_filename('haxby_face_vs_house.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Chance-level accuracy for this data\n",
    "\n",
    "Does the model above perform better than chance? To answer this question, we measure a score at random using simple strategies that are implemented in the nilearn.decoding.Decoder object. This is useful to inspect the decoding performance by comparing to a score at chance.\n",
    "\n",
    "Let’s define a object with Dummy estimator replacing ‘svc’ for classification setting. This object initializes estimator with default dummy strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_decoder = Decoder(estimator='dummy_classifier', mask=haxby_dataset.mask, cv=cv)\n",
    "dummy_decoder.fit(func_img, conditions, groups=session_label)\n",
    "\n",
    "# Now, we can compare these scores by simply taking a mean over folds\n",
    "print(dummy_decoder.cv_scores_['face'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
